{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, InputLayer\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import EfficientNetB0, ResNet50","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:03:00.997148Z","iopub.execute_input":"2023-04-24T20:03:00.998005Z","iopub.status.idle":"2023-04-24T20:03:01.010030Z","shell.execute_reply.started":"2023-04-24T20:03:00.997959Z","shell.execute_reply":"2023-04-24T20:03:01.008574Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def load_label_from_excel(csv_path='/kaggle/input/adiadas-nike-shoes/dataset/labelnames.csv'):\n    \"\"\"This function generates a dictionary mapping their names and labels\n\n    Args:\n        excel_path (string): the path where the excel path is kept\n    Returns:\n        dict: the image and label mapping dictionary\n    \"\"\"    \n    # load csv file\n    df = pd.read_csv(csv_path)\n    # initiate mapping variable\n    label_dict = {}\n    # populate dictionary\n    for _, row in df.iterrows():\n        if \".JPG\" in row['Name']:\n            row['Name'] = row['Name'][:-4]\n        label_dict[row['Name']] = row['Label']\n\n    return label_dict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-24T20:13:07.394526Z","iopub.execute_input":"2023-04-24T20:13:07.394912Z","iopub.status.idle":"2023-04-24T20:13:07.402104Z","shell.execute_reply.started":"2023-04-24T20:13:07.394878Z","shell.execute_reply":"2023-04-24T20:13:07.400715Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"label_dict = load_label_from_excel(csv_path='/kaggle/input/adiadas-nike-shoes/dataset/labelnames.csv')\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:13:59.265922Z","iopub.execute_input":"2023-04-24T20:13:59.266334Z","iopub.status.idle":"2023-04-24T20:13:59.354620Z","shell.execute_reply.started":"2023-04-24T20:13:59.266291Z","shell.execute_reply":"2023-04-24T20:13:59.353530Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'aadidas_ (10)': 'Adidas',\n 'aadidas_ (11)': 'Adidas',\n 'aadidas_ (12)': 'Adidas',\n 'aadidas_ (13)': 'Adidas',\n 'aadidas_ (14)': 'Adidas',\n 'aadidas_ (15)': 'Adidas',\n 'aadidas_ (16)': 'Adidas',\n 'aadidas_ (17)': 'Adidas',\n 'aadidas_ (18)': 'Adidas',\n 'aadidas_ (19)': 'Adidas',\n 'aadidas_ (2)': 'Adidas',\n 'aadidas_ (20)': 'Adidas',\n 'aadidas_ (21)': 'Adidas',\n 'aadidas_ (22)': 'Adidas',\n 'aadidas_ (23)': 'Adidas',\n 'aadidas_ (24)': 'Adidas',\n 'aadidas_ (3)': 'Adidas',\n 'aadidas_ (4)': 'Adidas',\n 'aadidas_ (5)': 'Adidas',\n 'aadidas_ (6)': 'Adidas',\n 'aadidas_ (7)': 'Adidas',\n 'aadidas_ (8)': 'Adidas',\n 'aadidas_ (9)': 'Adidas',\n 'Adidas (1)': 'Adidas',\n 'Adidas (10)': 'Adidas',\n 'Adidas (11)': 'Adidas',\n 'Adidas (12)': 'Adidas',\n 'Adidas (13)': 'Adidas',\n 'Adidas (14)': 'Adidas',\n 'Adidas (15)': 'Adidas',\n 'Adidas (16)': 'Adidas',\n 'Adidas (17)': 'Adidas',\n 'Adidas (18)': 'Adidas',\n 'Adidas (19)': 'Adidas',\n 'Adidas (2)': 'Adidas',\n 'Adidas (20)': 'Adidas',\n 'Adidas (21)': 'Adidas',\n 'Adidas (22)': 'Adidas',\n 'Adidas (23)': 'Adidas',\n 'Adidas (24)': 'Adidas',\n 'Adidas (25)': 'Adidas',\n 'Adidas (26)': 'Adidas',\n 'Adidas (27)': 'Adidas',\n 'Adidas (28)': 'Adidas',\n 'Adidas (29)': 'Adidas',\n 'Adidas (3)': 'Adidas',\n 'Adidas (30)': 'Adidas',\n 'Adidas (31)': 'Adidas',\n 'Adidas (32)': 'Adidas',\n 'Adidas (33)': 'Adidas',\n 'Adidas (34)': 'Adidas',\n 'Adidas (35)': 'Adidas',\n 'Adidas (36)': 'Adidas',\n 'Adidas (37)': 'Adidas',\n 'Adidas (38)': 'Adidas',\n 'Adidas (39)': 'Adidas',\n 'Adidas (4)': 'Adidas',\n 'Adidas (40)': 'Adidas',\n 'Adidas (41)': 'Adidas',\n 'Adidas (42)': 'Adidas',\n 'Adidas (43)': 'Adidas',\n 'Adidas (44)': 'Adidas',\n 'Adidas (45)': 'Adidas',\n 'Adidas (46)': 'Adidas',\n 'Adidas (47)': 'Adidas',\n 'Adidas (48)': 'Adidas',\n 'Adidas (49)': 'Adidas',\n 'Adidas (5)': 'Adidas',\n 'Adidas (50)': 'Adidas',\n 'Adidas (51)': 'Adidas',\n 'Adidas (52)': 'Adidas',\n 'Adidas (53)': 'Adidas',\n 'Adidas (54)': 'Adidas',\n 'Adidas (55)': 'Adidas',\n 'Adidas (56)': 'Adidas',\n 'Adidas (57)': 'Adidas',\n 'Adidas (58)': 'Adidas',\n 'Adidas (59)': 'Adidas',\n 'Adidas (6)': 'Adidas',\n 'Adidas (60)': 'Adidas',\n 'Adidas (61)': 'Adidas',\n 'Adidas (62)': 'Adidas',\n 'Adidas (63)': 'Adidas',\n 'Adidas (64)': 'Adidas',\n 'Adidas (65)': 'Adidas',\n 'Adidas (66)': 'Adidas',\n 'Adidas (67)': 'Adidas',\n 'Adidas (68)': 'Adidas',\n 'Adidas (69)': 'Adidas',\n 'Adidas (7)': 'Adidas',\n 'Adidas (70)': 'Adidas',\n 'Adidas (71)': 'Adidas',\n 'Adidas (72)': 'Adidas',\n 'Adidas (73)': 'Adidas',\n 'Adidas (74)': 'Adidas',\n 'Adidas (75)': 'Adidas',\n 'Adidas (76)': 'Adidas',\n 'Adidas (77)': 'Adidas',\n 'Adidas (78)': 'Adidas',\n 'Adidas (79)': 'Adidas',\n 'Adidas (8)': 'Adidas',\n 'Adidas (80)': 'Adidas',\n 'Adidas (81)': 'Adidas',\n 'Adidas (82)': 'Adidas',\n 'Adidas (83)': 'Adidas',\n 'Adidas (84)': 'Adidas',\n 'Adidas (85)': 'Adidas',\n 'Adidas (86)': 'Adidas',\n 'Adidas (87)': 'Adidas',\n 'Adidas (88)': 'Adidas',\n 'Adidas (89)': 'Adidas',\n 'Adidas (9)': 'Adidas',\n 'adidass_(11)': 'Adidas',\n 'adidass_(12)': 'Adidas',\n 'adidass_(13)': 'Adidas',\n 'adidass_(14)': 'Adidas',\n 'adidass_(15)': 'Adidas',\n 'adidass_(16)': 'Adidas',\n 'adidass_(17)': 'Adidas',\n 'adidass_(18)': 'Adidas',\n 'adidass_(19)': 'Adidas',\n 'adidass_(20)': 'Adidas',\n 'adidass_(21)': 'Adidas',\n 'adidass_(22)': 'Adidas',\n 'adidass_(23)': 'Adidas',\n 'adidass_(24)': 'Adidas',\n 'adidass_(25)': 'Adidas',\n 'adidass_(26)': 'Adidas',\n 'adidass_(27)': 'Adidas',\n 'adidass_(28)': 'Adidas',\n 'adidass_(29)': 'Adidas',\n 'adidass_(30)': 'Adidas',\n 'adidas_ (1)': 'Adidas',\n 'adidas_ (10)': 'Adidas',\n 'adidas_ (100)': 'Adidas',\n 'adidas_ (101)': 'Adidas',\n 'adidas_ (102)': 'Adidas',\n 'adidas_ (103)': 'Adidas',\n 'adidas_ (104)': 'Adidas',\n 'adidas_ (105)': 'Adidas',\n 'adidas_ (106)': 'Adidas',\n 'adidas_ (107)': 'Adidas',\n 'adidas_ (108)': 'Adidas',\n 'adidas_ (109)': 'Adidas',\n 'adidas_ (11)': 'Adidas',\n 'adidas_ (110)': 'Adidas',\n 'adidas_ (111)': 'Adidas',\n 'adidas_ (112)': 'Adidas',\n 'adidas_ (113)': 'Adidas',\n 'adidas_ (114)': 'Adidas',\n 'adidas_ (115)': 'Adidas',\n 'adidas_ (116)': 'Adidas',\n 'adidas_ (117)': 'Adidas',\n 'adidas_ (118)': 'Adidas',\n 'adidas_ (119)': 'Adidas',\n 'adidas_ (12)': 'Adidas',\n 'adidas_ (120)': 'Adidas',\n 'adidas_ (121)': 'Adidas',\n 'adidas_ (122)': 'Adidas',\n 'adidas_ (123)': 'Adidas',\n 'adidas_ (124)': 'Adidas',\n 'adidas_ (125)': 'Adidas',\n 'adidas_ (126)': 'Adidas',\n 'adidas_ (127)': 'Adidas',\n 'adidas_ (128)': 'Adidas',\n 'adidas_ (129)': 'Adidas',\n 'adidas_ (13)': 'Adidas',\n 'adidas_ (130)': 'Adidas',\n 'adidas_ (131)': 'Adidas',\n 'adidas_ (132)': 'Adidas',\n 'adidas_ (133)': 'Adidas',\n 'adidas_ (134)': 'Adidas',\n 'adidas_ (135)': 'Adidas',\n 'adidas_ (136)': 'Adidas',\n 'adidas_ (137)': 'Adidas',\n 'adidas_ (138)': 'Adidas',\n 'adidas_ (139)': 'Adidas',\n 'adidas_ (14)': 'Adidas',\n 'adidas_ (140)': 'Adidas',\n 'adidas_ (141)': 'Adidas',\n 'adidas_ (142)': 'Adidas',\n 'adidas_ (143)': 'Adidas',\n 'adidas_ (144)': 'Adidas',\n 'adidas_ (145)': 'Adidas',\n 'adidas_ (146)': 'Adidas',\n 'adidas_ (147)': 'Adidas',\n 'adidas_ (148)': 'Adidas',\n 'adidas_ (149)': 'Adidas',\n 'adidas_ (15)': 'Adidas',\n 'adidas_ (150)': 'Adidas',\n 'adidas_ (151)': 'Adidas',\n 'adidas_ (152)': 'Adidas',\n 'adidas_ (153)': 'Adidas',\n 'adidas_ (154)': 'Adidas',\n 'adidas_ (155)': 'Adidas',\n 'adidas_ (16)': 'Adidas',\n 'adidas_ (17)': 'Adidas',\n 'adidas_ (18)': 'Adidas',\n 'adidas_ (19)': 'Adidas',\n 'adidas_ (2)': 'Adidas',\n 'adidas_ (20)': 'Adidas',\n 'adidas_ (21)': 'Adidas',\n 'adidas_ (22)': 'Adidas',\n 'adidas_ (23)': 'Adidas',\n 'adidas_ (24)': 'Adidas',\n 'adidas_ (25)': 'Adidas',\n 'adidas_ (26)': 'Adidas',\n 'adidas_ (27)': 'Adidas',\n 'adidas_ (28)': 'Adidas',\n 'adidas_ (29)': 'Adidas',\n 'adidas_ (3)': 'Adidas',\n 'adidas_ (30)': 'Adidas',\n 'adidas_ (31)': 'Adidas',\n 'adidas_ (32)': 'Adidas',\n 'adidas_ (33)': 'Adidas',\n 'adidas_ (34)': 'Adidas',\n 'adidas_ (35)': 'Adidas',\n 'adidas_ (36)': 'Adidas',\n 'adidas_ (37)': 'Adidas',\n 'adidas_ (38)': 'Adidas',\n 'adidas_ (39)': 'Adidas',\n 'adidas_ (4)': 'Adidas',\n 'adidas_ (40)': 'Adidas',\n 'adidas_ (41)': 'Adidas',\n 'adidas_ (42)': 'Adidas',\n 'adidas_ (43)': 'Adidas',\n 'adidas_ (44)': 'Adidas',\n 'adidas_ (45)': 'Adidas',\n 'adidas_ (46)': 'Adidas',\n 'adidas_ (47)': 'Adidas',\n 'adidas_ (48)': 'Adidas',\n 'adidas_ (49)': 'Adidas',\n 'adidas_ (5)': 'Adidas',\n 'adidas_ (50)': 'Adidas',\n 'adidas_ (51)': 'Adidas',\n 'adidas_ (52)': 'Adidas',\n 'adidas_ (53)': 'Adidas',\n 'adidas_ (54)': 'Adidas',\n 'adidas_ (55)': 'Adidas',\n 'adidas_ (56)': 'Adidas',\n 'adidas_ (57)': 'Adidas',\n 'adidas_ (58)': 'Adidas',\n 'adidas_ (59)': 'Adidas',\n 'adidas_ (6)': 'Adidas',\n 'adidas_ (60)': 'Adidas',\n 'adidas_ (61)': 'Adidas',\n 'adidas_ (62)': 'Adidas',\n 'adidas_ (63)': 'Adidas',\n 'adidas_ (64)': 'Adidas',\n 'adidas_ (65)': 'Adidas',\n 'adidas_ (66)': 'Adidas',\n 'adidas_ (67)': 'Adidas',\n 'adidas_ (68)': 'Adidas',\n 'adidas_ (69)': 'Adidas',\n 'adidas_ (7)': 'Adidas',\n 'adidas_ (70)': 'Adidas',\n 'adidas_ (71)': 'Adidas',\n 'adidas_ (72)': 'Adidas',\n 'adidas_ (73)': 'Adidas',\n 'adidas_ (74)': 'Adidas',\n 'adidas_ (75)': 'Adidas',\n 'adidas_ (76)': 'Adidas',\n 'adidas_ (77)': 'Adidas',\n 'adidas_ (78)': 'Adidas',\n 'adidas_ (79)': 'Adidas',\n 'adidas_ (8)': 'Adidas',\n 'adidas_ (80)': 'Adidas',\n 'adidas_ (81)': 'Adidas',\n 'adidas_ (82)': 'Adidas',\n 'adidas_ (83)': 'Adidas',\n 'adidas_ (84)': 'Adidas',\n 'adidas_ (85)': 'Adidas',\n 'adidas_ (86)': 'Adidas',\n 'adidas_ (87)': 'Adidas',\n 'adidas_ (88)': 'Adidas',\n 'adidas_ (89)': 'Adidas',\n 'adidas_ (9)': 'Adidas',\n 'adidas_ (90)': 'Adidas',\n 'adidas_ (91)': 'Adidas',\n 'adidas_ (92)': 'Adidas',\n 'adidas_ (93)': 'Adidas',\n 'adidas_ (94)': 'Adidas',\n 'adidas_ (95)': 'Adidas',\n 'adidas_ (96)': 'Adidas',\n 'adidas_ (97)': 'Adidas',\n 'adidas_ (98)': 'Adidas',\n 'adidas_ (99)': 'Adidas',\n 'adidas_down': 'Adidas',\n 'Image_1': 'Nike',\n 'Image_10': 'Nike',\n 'Image_100': 'Nike',\n 'Image_101': 'Nike',\n 'Image_102': 'Nike',\n 'Image_103': 'Nike',\n 'Image_104': 'Nike',\n 'Image_105': 'Nike',\n 'Image_106': 'Nike',\n 'Image_107': 'Nike',\n 'Image_108': 'Nike',\n 'Image_109': 'Nike',\n 'Image_11': 'Nike',\n 'Image_110': 'Nike',\n 'Image_111': 'Nike',\n 'Image_112': 'Nike',\n 'Image_113': 'Nike',\n 'Image_114': 'Nike',\n 'Image_115': 'Nike',\n 'Image_116': 'Nike',\n 'Image_117': 'Nike',\n 'Image_118': 'Nike',\n 'Image_119': 'Nike',\n 'Image_12': 'Nike',\n 'Image_120': 'Nike',\n 'Image_121': 'Nike',\n 'Image_122': 'Nike',\n 'Image_123': 'Nike',\n 'Image_124': 'Nike',\n 'Image_125': 'Nike',\n 'Image_126': 'Nike',\n 'Image_127': 'Nike',\n 'Image_128': 'Nike',\n 'Image_129': 'Nike',\n 'Image_13': 'Nike',\n 'Image_130': 'Nike',\n 'Image_131': 'Nike',\n 'Image_132': 'Nike',\n 'Image_133': 'Nike',\n 'Image_134': 'Nike',\n 'Image_135': 'Nike',\n 'Image_136': 'Nike',\n 'Image_137': 'Nike',\n 'Image_138': 'Nike',\n 'Image_139': 'Nike',\n 'Image_14': 'Nike',\n 'Image_140': 'Nike',\n 'Image_141': 'Nike',\n 'Image_142': 'Nike',\n 'Image_143': 'Nike',\n 'Image_144': 'Nike',\n 'Image_145': 'Nike',\n 'Image_146': 'Nike',\n 'Image_147': 'Nike',\n 'Image_148': 'Nike',\n 'Image_149': 'Nike',\n 'Image_15': 'Nike',\n 'Image_150': 'Nike',\n 'Image_151': 'Nike',\n 'Image_152': 'Nike',\n 'Image_153': 'Nike',\n 'Image_154': 'Nike',\n 'Image_155': 'Nike',\n 'Image_156': 'Nike',\n 'Image_157': 'Nike',\n 'Image_158': 'Nike',\n 'Image_159': 'Nike',\n 'Image_16': 'Nike',\n 'Image_160': 'Nike',\n 'Image_161': 'Nike',\n 'Image_162': 'Nike',\n 'Image_163': 'Nike',\n 'Image_164': 'Nike',\n 'Image_165': 'Nike',\n 'Image_166': 'Nike',\n 'Image_167': 'Nike',\n 'Image_168': 'Nike',\n 'Image_169': 'Nike',\n 'Image_17': 'Nike',\n 'Image_170': 'Nike',\n 'Image_171': 'Nike',\n 'Image_172': 'Nike',\n 'Image_173': 'Nike',\n 'Image_174': 'Nike',\n 'Image_175': 'Nike',\n 'Image_176': 'Nike',\n 'Image_177': 'Nike',\n 'Image_178': 'Nike',\n 'Image_179': 'Nike',\n 'Image_18': 'Nike',\n 'Image_180': 'Nike',\n 'Image_181': 'Nike',\n 'Image_182': 'Nike',\n 'Image_183': 'Nike',\n 'Image_184': 'Nike',\n 'Image_185': 'Nike',\n 'Image_186': 'Nike',\n 'Image_187': 'Nike',\n 'Image_188': 'Nike',\n 'Image_189': 'Nike',\n 'Image_19': 'Nike',\n 'Image_190': 'Nike',\n 'Image_191': 'Nike',\n 'Image_192': 'Nike',\n 'Image_193': 'Nike',\n 'Image_194': 'Nike',\n 'Image_195': 'Nike',\n 'Image_196': 'Nike',\n 'Image_197': 'Nike',\n 'Image_198': 'Nike',\n 'Image_199': 'Nike',\n 'Image_2': 'Nike',\n 'Image_20': 'Nike',\n 'Image_200': 'Nike',\n 'Image_201': 'Nike',\n 'Image_202': 'Nike',\n 'Image_203': 'Nike',\n 'Image_204': 'Nike',\n 'Image_205': 'Nike',\n 'Image_206': 'Nike',\n 'Image_207': 'Nike',\n 'Image_208': 'Nike',\n 'Image_209': 'Nike',\n 'Image_21': 'Nike',\n 'Image_210': 'Nike',\n 'Image_211': 'Nike',\n 'Image_212': 'Nike',\n 'Image_213': 'Nike',\n 'Image_214': 'Nike',\n 'Image_215': 'Nike',\n 'Image_216': 'Nike',\n 'Image_217': 'Nike',\n 'Image_218': 'Nike',\n 'Image_219': 'Nike',\n 'Image_22': 'Nike',\n 'Image_220': 'Nike',\n 'Image_221': 'Nike',\n 'Image_222': 'Nike',\n 'Image_223': 'Nike',\n 'Image_224': 'Nike',\n 'Image_225': 'Nike',\n 'Image_226': 'Nike',\n 'Image_227': 'Nike',\n 'Image_228': 'Nike',\n 'Image_229': 'Nike',\n 'Image_23': 'Nike',\n 'Image_230': 'Nike',\n 'Image_231': 'Nike',\n 'Image_232': 'Nike',\n 'Image_233': 'Nike',\n 'Image_234': 'Nike',\n 'Image_235': 'Nike',\n 'Image_236': 'Nike',\n 'Image_237': 'Nike',\n 'Image_238': 'Nike',\n 'Image_239': 'Nike',\n 'Image_24': 'Nike',\n 'Image_240': 'Nike',\n 'Image_241': 'Nike',\n 'Image_242': 'Nike',\n 'Image_243': 'Nike',\n 'Image_244': 'Nike',\n 'Image_245': 'Nike',\n 'Image_246': 'Nike',\n 'Image_247': 'Nike',\n 'Image_248': 'Nike',\n 'Image_249': 'Nike',\n 'Image_25': 'Nike',\n 'Image_250': 'Nike',\n 'Image_251': 'Nike',\n 'Image_252': 'Nike',\n 'Image_253': 'Nike',\n 'Image_254': 'Nike',\n 'Image_255': 'Nike',\n 'Image_256': 'Nike',\n 'Image_257': 'Nike',\n 'Image_258': 'Nike',\n 'Image_259': 'Nike',\n 'Image_26': 'Nike',\n 'Image_260': 'Nike',\n 'Image_261': 'Nike',\n 'Image_262': 'Nike',\n 'Image_263': 'Nike',\n 'Image_264': 'Nike',\n 'Image_265': 'Nike',\n 'Image_266': 'Nike',\n 'Image_267': 'Nike',\n 'Image_268': 'Nike',\n 'Image_269': 'Nike',\n 'Image_27': 'Nike',\n 'Image_270': 'Nike',\n 'Image_271': 'Nike',\n 'Image_272': 'Nike',\n 'Image_273': 'Nike',\n 'Image_274': 'Nike',\n 'Image_275': 'Nike',\n 'Image_276': 'Nike',\n 'Image_277': 'Nike',\n 'Image_278': 'Nike',\n 'Image_279': 'Nike',\n 'Image_28': 'Nike',\n 'Image_280': 'Nike',\n 'Image_281': 'Nike',\n 'Image_282': 'Nike',\n 'Image_289': 'Nike',\n 'Image_29': 'Nike',\n 'Image_290': 'Nike',\n 'Image_291': 'Nike',\n 'Image_292': 'Nike',\n 'Image_299': 'Nike',\n 'Image_3': 'Nike',\n 'Image_30': 'Nike',\n 'Image_300': 'Nike',\n 'Image_31': 'Nike',\n 'Image_32': 'Nike',\n 'Image_33': 'Nike',\n 'Image_34': 'Nike',\n 'Image_35': 'Nike',\n 'Image_36': 'Nike',\n 'Image_37': 'Nike',\n 'Image_38': 'Nike',\n 'Image_39': 'Nike',\n 'Image_4': 'Nike',\n 'Image_40': 'Nike',\n 'Image_41': 'Nike',\n 'Image_42': 'Nike',\n 'Image_43': 'Nike',\n 'Image_44': 'Nike',\n 'Image_45': 'Nike',\n 'Image_46': 'Nike',\n 'Image_47': 'Nike',\n 'Image_48': 'Nike',\n 'Image_49': 'Nike',\n 'Image_5': 'Nike',\n 'Image_50': 'Nike',\n 'Image_51': 'Nike',\n 'Image_52': 'Nike',\n 'Image_53': 'Nike',\n 'Image_54': 'Nike',\n 'Image_55': 'Nike',\n 'Image_56': 'Nike',\n 'Image_57': 'Nike',\n 'Image_58': 'Nike',\n 'Image_59': 'Nike',\n 'Image_6': 'Nike',\n 'Image_60': 'Nike',\n 'Image_61': 'Nike',\n 'Image_62': 'Nike',\n 'Image_63': 'Nike',\n 'Image_64': 'Nike',\n 'Image_65': 'Nike',\n 'Image_66': 'Nike',\n 'Image_67': 'Nike',\n 'Image_68': 'Nike',\n 'Image_69': 'Nike',\n 'Image_7': 'Nike',\n 'Image_70': 'Nike',\n 'Image_71': 'Nike',\n 'Image_72': 'Nike',\n 'Image_73': 'Nike',\n 'Image_74': 'Nike',\n 'Image_75': 'Nike',\n 'Image_76': 'Nike',\n 'Image_77': 'Nike',\n 'Image_78': 'Nike',\n 'Image_79': 'Nike',\n 'Image_8': 'Nike',\n 'Image_80': 'Nike',\n 'Image_81': 'Nike',\n 'Image_82': 'Nike',\n 'Image_83': 'Nike',\n 'Image_84': 'Nike',\n 'Image_85': 'Nike',\n 'Image_86': 'Nike',\n 'Image_87': 'Nike',\n 'Image_88': 'Nike',\n 'Image_89': 'Nike',\n 'Image_9': 'Nike',\n 'Image_90': 'Nike',\n 'Image_91': 'Nike',\n 'Image_92': 'Nike',\n 'Image_93': 'Nike',\n 'Image_94': 'Nike',\n 'Image_95': 'Nike',\n 'Image_96': 'Nike',\n 'Image_97': 'Nike',\n 'Image_98': 'Nike',\n 'Image_99': 'Nike'}"},"metadata":{}}]},{"cell_type":"code","source":"def transform_data(Set, path, label_dict, increase_train_image):\n    \"\"\"the functions process the input images for model training\n    Args:\n        Set (string): the set which to be converted\n        path (string): the path where the images are kept\n        label_dict(dictionary): the dictionary containing show and label mapping\n        increase_train_image (bool): the flag whether to crop image for image augmentation in the training set\n    Returns:\n        np.array, np.array: processed train images and their corresponding labels\n    \"\"\"    \n    data = []\n    label = []\n    for class_name in os.listdir(path):\n        for img_name in os.listdir(os.path.join(path, class_name)):\n            # for windows\n            img_path = path + '/' + class_name + '/' + img_name \n\n            # read, resize and normalize image\n            org_img = cv2.imread(img_path)\n            img = cv2.resize(org_img , (224, 224))\n            img = tf.keras.utils.normalize(img, axis=1)\n\n            label_name = label_dict[img_name[:-4]]\n            img_label = 0 if label_name == 'Adidas' else 1\n\n            # print(img_name, img_label)\n            data.append(img)\n            label.append(img_label)\n\n            if Set == 'train' and increase_train_image:\n                # left crop\n                crop_left = org_img[:,size:,:]\n                crop_left = cv2.resize(crop_left , (224, 224))\n                crop_left = tf.keras.utils.normalize(img, axis=1)\n                data.append(crop_left)\n                label.append(img_label)\n                # right crop\n                crop_right = org_img[:, :-size, :]\n                crop_right = cv2.resize(crop_right , (224, 224))\n                crop_right = tf.keras.utils.normalize(img, axis=1)\n                data.append(crop_right)\n                label.append(img_label)\n                # top crop\n                crop_top = org_img[size:, :, :]\n                crop_top = cv2.resize(crop_top , (224, 224))\n                crop_top = tf.keras.utils.normalize(img, axis=1)\n                data.append(crop_top)\n                label.append(img_label)\n                # bottom crop\n                crop_bottom = org_img[:-size, :, :]\n                crop_bottom = cv2.resize(crop_bottom , (224, 224))\n                crop_bottom = tf.keras.utils.normalize(img, axis=1)\n                data.append(crop_bottom)\n                label.append(img_label)\n\n    print(\"***Successfully Converted Data***\")\n        \n    return np.array(data), np.array(label, dtype=np.uint8)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:24:57.019200Z","iopub.execute_input":"2023-04-24T20:24:57.019642Z","iopub.status.idle":"2023-04-24T20:24:57.035757Z","shell.execute_reply.started":"2023-04-24T20:24:57.019599Z","shell.execute_reply":"2023-04-24T20:24:57.034363Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_data, train_label = transform_data('train', '/kaggle/input/adiadas-nike-shoes/dataset/train', label_dict, False)\ntest_data, test_label = transform_data('test', '/kaggle/input/adiadas-nike-shoes/dataset/test', label_dict, False)\nval_data, val_label = transform_data('val', '/kaggle/input/adiadas-nike-shoes/dataset/validation', label_dict, False)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:26:15.127136Z","iopub.execute_input":"2023-04-24T20:26:15.128350Z","iopub.status.idle":"2023-04-24T20:26:19.394097Z","shell.execute_reply.started":"2023-04-24T20:26:15.128301Z","shell.execute_reply":"2023-04-24T20:26:19.392634Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"***Successfully Converted Data***\n***Successfully Converted Data***\n***Successfully Converted Data***\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:26:26.684600Z","iopub.execute_input":"2023-04-24T20:26:26.685038Z","iopub.status.idle":"2023-04-24T20:26:26.701494Z","shell.execute_reply.started":"2023-04-24T20:26:26.684999Z","shell.execute_reply":"2023-04-24T20:26:26.700389Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"array([[[[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        ...,\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]]],\n\n\n       [[[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        ...,\n\n        [[0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648],\n         ...,\n         [0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648]],\n\n        [[0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         ...,\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531],\n         [0.06681531, 0.06681531, 0.06681531]],\n\n        [[0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648],\n         ...,\n         [0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648],\n         [0.06681648, 0.06681648, 0.06681648]]],\n\n\n       [[[0.08141971, 0.08126434, 0.06987242],\n         [0.08141971, 0.08126434, 0.06987242],\n         [0.08185511, 0.08126434, 0.06987242],\n         ...,\n         [0.02743017, 0.02934546, 0.05838229],\n         [0.02699477, 0.02896923, 0.05807175],\n         [0.02699477, 0.02896923, 0.05807175]],\n\n        [[0.08154091, 0.08144152, 0.07000139],\n         [0.08066882, 0.08068743, 0.06937916],\n         [0.08110487, 0.08106448, 0.06969028],\n         ...,\n         [0.027471  , 0.02940944, 0.05849005],\n         [0.02703496, 0.02903239, 0.05817894],\n         [0.02659891, 0.02865535, 0.05786782]],\n\n        [[0.08122325, 0.08130135, 0.06974924],\n         [0.08122325, 0.08130135, 0.06974924],\n         [0.08166468, 0.08168305, 0.07006343],\n         ...,\n         [0.02781014, 0.02977233, 0.05906692],\n         [0.02825157, 0.03015402, 0.05938111],\n         [0.02825157, 0.03015402, 0.05938111]],\n\n        ...,\n\n        [[0.05608698, 0.08044785, 0.05986556],\n         [0.10750004, 0.12315473, 0.08560775],\n         [0.10282612, 0.11520927, 0.0808185 ],\n         ...,\n         [0.09932069, 0.11222972, 0.07782523],\n         [0.09347829, 0.1072638 , 0.07483195],\n         [0.13554353, 0.1430184 , 0.09638355]],\n\n        [[0.10674808, 0.12294732, 0.08731544],\n         [0.15199998, 0.1603233 , 0.10959593],\n         [0.1345954 , 0.14261889, 0.09815459],\n         ...,\n         [0.0893435 , 0.10327575, 0.0734654 ],\n         [0.11835113, 0.12786521, 0.08851979],\n         [0.10558777, 0.11704585, 0.08189586]],\n\n        [[0.1151903 , 0.12897158, 0.09304655],\n         [0.1174055 , 0.12991298, 0.09304655],\n         [0.13180428, 0.13932697, 0.09838043],\n         ...,\n         [0.12183589, 0.12991298, 0.09186124],\n         [0.12072829, 0.12897158, 0.09126859],\n         [0.09193072, 0.10449522, 0.07585961]]],\n\n\n       ...,\n\n\n       [[[0.06277335, 0.07603473, 0.03313881],\n         [0.06242267, 0.07384142, 0.03802814],\n         [0.06066922, 0.07128256, 0.04183096],\n         ...,\n         [0.05365544, 0.03765182, 0.07442651],\n         [0.06066922, 0.04167288, 0.0825754 ],\n         [0.06838438, 0.05373609, 0.09398384]],\n\n        [[0.06037089, 0.07456955, 0.02660727],\n         [0.059324  , 0.07167364, 0.0298653 ],\n         [0.06071986, 0.07167364, 0.0396394 ],\n         ...,\n         [0.0523447 , 0.03583682, 0.07384875],\n         [0.06281364, 0.04416255, 0.08796689],\n         [0.06071986, 0.04488652, 0.08470886]],\n\n        [[0.06114688, 0.07549912, 0.02514946],\n         [0.06324334, 0.07586036, 0.03335037],\n         [0.06149629, 0.07224796, 0.03663074],\n         ...,\n         [0.05136338, 0.03504026, 0.07107456],\n         [0.05520689, 0.03684646, 0.07818202],\n         [0.06673745, 0.04985109, 0.09677075]],\n\n        ...,\n\n        [[0.02242567, 0.0229173 , 0.08392358],\n         [0.02285693, 0.0246024 , 0.08392358],\n         [0.01897557, 0.02898365, 0.0586454 ],\n         ...,\n         [0.09358405, 0.07684038, 0.150658  ],\n         [0.09574036, 0.07852547, 0.14863574],\n         [0.09401531, 0.07684038, 0.14661349]],\n\n        [[0.03791929, 0.05809207, 0.04517004],\n         [0.03530417, 0.06178579, 0.02669139],\n         [0.03617588, 0.0654795 , 0.02361161],\n         ...,\n         [0.09719543, 0.07823961, 0.16014832],\n         [0.09327275, 0.07588906, 0.14269626],\n         [0.09327275, 0.07521748, 0.14474944]],\n\n        [[0.03976055, 0.0645968 , 0.02103632],\n         [0.03578449, 0.0642586 , 0.01472543],\n         [0.03622628, 0.06662602, 0.02419177],\n         ...,\n         [0.09409996, 0.07474289, 0.1567206 ],\n         [0.09630888, 0.07677211, 0.1567206 ],\n         [0.09807602, 0.07880133, 0.15461696]]],\n\n\n       [[[0.08528581, 0.08455811, 0.0770055 ],\n         [0.08528581, 0.08455811, 0.0770055 ],\n         [0.08593684, 0.08515781, 0.07751548],\n         ...,\n         [0.02994769, 0.03478277, 0.02804836],\n         [0.02994769, 0.03298366, 0.02651845],\n         [0.02994769, 0.03298366, 0.02651845]],\n\n        [[0.08839301, 0.08664157, 0.0790162 ],\n         [0.08839301, 0.08664157, 0.0790162 ],\n         [0.08904296, 0.0872391 , 0.07952598],\n         ...,\n         [0.02729784, 0.03226652, 0.0254891 ],\n         [0.02729784, 0.03166899, 0.0254891 ],\n         [0.02664789, 0.03107146, 0.02497931]],\n\n        [[0.09228736, 0.0895987 , 0.08123205],\n         [0.09228736, 0.0895987 , 0.08123205],\n         [0.09293273, 0.09019207, 0.08173975],\n         ...,\n         [0.02710538, 0.03144855, 0.02538502],\n         [0.02775074, 0.03204192, 0.02589272],\n         [0.02646001, 0.03085518, 0.02487731]],\n\n        ...,\n\n        [[0.05519712, 0.05754581, 0.0588602 ],\n         [0.08430105, 0.0844624 , 0.08284028],\n         [0.09132614, 0.09188767, 0.09025231],\n         ...,\n         [0.02860214, 0.02738067, 0.02616009],\n         [0.03161289, 0.03016514, 0.0287761 ],\n         [0.0376344 , 0.03573409, 0.03400812]],\n\n        [[0.04936027, 0.05248624, 0.05460363],\n         [0.07058519, 0.07211153, 0.07180163],\n         [0.07453401, 0.07667555, 0.07610113],\n         ...,\n         [0.03257778, 0.03057894, 0.02966654],\n         [0.03159057, 0.03057894, 0.02923659],\n         [0.04393064, 0.04244539, 0.04041529]],\n\n        [[0.03149678, 0.03718862, 0.03844251],\n         [0.08140707, 0.08020197, 0.07984213],\n         [0.08770643, 0.08557864, 0.08491147],\n         ...,\n         [0.03585788, 0.03405223, 0.03252828],\n         [0.03924984, 0.03718862, 0.03548539],\n         [0.05184855, 0.04883807, 0.04689141]]],\n\n\n       [[[0.06944121, 0.07230321, 0.07342029],\n         [0.06916233, 0.07199942, 0.0730835 ],\n         [0.06916233, 0.07199942, 0.0730835 ],\n         ...,\n         [0.06525801, 0.06410075, 0.06365337],\n         [0.06525801, 0.06410075, 0.06365337],\n         [0.06525801, 0.06410075, 0.06365337]],\n\n        [[0.06798968, 0.07074036, 0.07170082],\n         [0.06770989, 0.07043544, 0.07136261],\n         [0.06770989, 0.07043544, 0.07136261],\n         ...,\n         [0.06547154, 0.06433714, 0.06392195],\n         [0.06547154, 0.06433714, 0.06392195],\n         [0.06547154, 0.06433714, 0.06392195]],\n\n        [[0.06659617, 0.06928679, 0.07012778],\n         [0.06631518, 0.06898021, 0.06978735],\n         [0.06715816, 0.06898021, 0.07012778],\n         ...,\n         [0.06575318, 0.06438153, 0.06400011],\n         [0.06547219, 0.06438153, 0.06400011],\n         [0.06547219, 0.06438153, 0.06400011]],\n\n        ...,\n\n        [[0.06968122, 0.06630567, 0.06651569],\n         [0.07601588, 0.07214607, 0.07216953],\n         [0.08123266, 0.0769558 , 0.07682562],\n         ...,\n         [0.06968122, 0.06802343, 0.07050663],\n         [0.06148343, 0.06115238, 0.06385506],\n         [0.05999293, 0.05977817, 0.06252475]],\n\n        [[0.06282756, 0.06013216, 0.05972901],\n         [0.06661235, 0.06362822, 0.06310353],\n         [0.06169212, 0.05908334, 0.05871666],\n         ...,\n         [0.06471995, 0.06362822, 0.0661406 ],\n         [0.05185166, 0.05139202, 0.05534214],\n         [0.05639341, 0.05558729, 0.05939156]],\n\n        [[0.07718413, 0.07357848, 0.07267764],\n         [0.07681659, 0.07323784, 0.07234879],\n         [0.05549907, 0.05348065, 0.05327501],\n         ...,\n         [0.05035346, 0.05041488, 0.05327501],\n         [0.06064468, 0.05961219, 0.06314076],\n         [0.05880696, 0.05790899, 0.06149647]]]])"},"metadata":{}}]},{"cell_type":"code","source":"def simple_CNN_model():\n    \"\"\"This function defines a simple CNN model\n    Returns:\n        tf.keras.model: return the defined model\n    \"\"\" \n    # initiate a sequential model\n    model = Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(224, 224, 3)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.Dense(2, activation='softmax'))\n    model.summary()\n    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n    metrics='accuracy')\n    # print model summary\n    model.summary()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:26:45.613941Z","iopub.execute_input":"2023-04-24T20:26:45.614376Z","iopub.status.idle":"2023-04-24T20:26:45.625958Z","shell.execute_reply.started":"2023-04-24T20:26:45.614338Z","shell.execute_reply":"2023-04-24T20:26:45.624659Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def efficientnet():\n    \"\"\"This function defines the backbone of a efficientnet model\n    Returns:\n        tf.keras.model: return the defined model\n    \"\"\" \n    # define input layer\n    inputs = layers.Input(shape=(224, 224, 3))\n    # add augmentation layer\n    # x = img_augmentation(inputs)\n    # define efficientnet config\n    outputs = EfficientNetB0(include_top=True, weights=None, classes=2)(inputs)\n    # generate the effcienet model\n    model = tf.keras.Model(inputs, outputs)\n    # compile the model\n    model.compile(\n        optimizer=\"adam\", \n        loss=\"sparse_categorical_crossentropy\", \n        metrics=[\"accuracy\"]\n    )\n    # print model summary\n    model.summary()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-24T21:36:27.246267Z","iopub.execute_input":"2023-04-24T21:36:27.246718Z","iopub.status.idle":"2023-04-24T21:36:27.255185Z","shell.execute_reply.started":"2023-04-24T21:36:27.246677Z","shell.execute_reply":"2023-04-24T21:36:27.253630Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"def plot_hist(history, figure_name):\n    \"\"\" This function plot the accuracy given history of a model\n    Args:\n        history (object of dicionary): the history of a model\n        figure_name (string): the suffix of the name of figure which willl show the accuracy\n    \"\"\"    \n    plt.plot(history.history[\"accuracy\"])\n    plt.plot(history.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.savefig(\"/kaggle/working/logs/\" + figure_name + '_accuracy_comparison' + 'CNN' + '.png')\n    # clear plt buffer\n    plt.clf()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:57:25.169384Z","iopub.execute_input":"2023-04-24T20:57:25.169831Z","iopub.status.idle":"2023-04-24T20:57:25.178228Z","shell.execute_reply.started":"2023-04-24T20:57:25.169790Z","shell.execute_reply":"2023-04-24T20:57:25.176669Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def train_CNN_model(train_data, train_label, val_data, val_label, tensorboard, pre_trained):\n    \"\"\"This functions trains the resnet model based on given parameters\n    Args:\n        train_data (list): the np array of training data\n        train_label (list): the np array of training labels\n        test_data (list): the np array of validation data\n        test_label (list): the bp array of validation labels\n        tensorboard (callback): tensorboard log callback\n        pre_trained (bool): this flag defines whether to use pre trained model or not\n    \"\"\" \n    print(\"***Initiating Model : Simple CNN\")\n    model = simple_CNN_model()\n    # define checkpoint for saving the best model\n    cp_callback = ModelCheckpoint(filepath='/kaggle/working/checkpoints/CNN_best_' + 'iter1.h5' ,save_weights_only=False, save_best_only=True, verbose=1)\n    # load pre-trained model\n    if(pre_trained):\n        model.load_weights(config.paths['pre_trained_model_path'])\n    # train the model\n    history_CNN = model.fit(train_data, train_label, \n                batch_size=4, \n                epochs=30,\n                validation_data=(val_data, val_label), \n                shuffle=True, \n                callbacks=[tensorboard, cp_callback])\n    # save the model of the last epoch\n    model.save(\"/kaggle/working/models/CNN_last_\" + 'iter_1.h5')\n    print(\"***Simple CNN Model Training Finished***\")\n    plot_hist(history_CNN, figure_name=\"CNN\")","metadata":{"execution":{"iopub.status.busy":"2023-04-24T21:49:44.029113Z","iopub.execute_input":"2023-04-24T21:49:44.029552Z","iopub.status.idle":"2023-04-24T21:49:44.038561Z","shell.execute_reply.started":"2023-04-24T21:49:44.029514Z","shell.execute_reply":"2023-04-24T21:49:44.037254Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"tensorboard = TensorBoard(log_dir=\"logs/{}\".format('CNN'))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T21:49:47.185393Z","iopub.execute_input":"2023-04-24T21:49:47.185859Z","iopub.status.idle":"2023-04-24T21:49:47.191848Z","shell.execute_reply.started":"2023-04-24T21:49:47.185814Z","shell.execute_reply":"2023-04-24T21:49:47.190949Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"train_CNN_model(train_data, train_label, val_data, val_label, tensorboard, False)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T21:49:49.612325Z","iopub.execute_input":"2023-04-24T21:49:49.612764Z","iopub.status.idle":"2023-04-24T22:09:51.750244Z","shell.execute_reply.started":"2023-04-24T21:49:49.612724Z","shell.execute_reply":"2023-04-24T22:09:51.749058Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"***Initiating Model : Simple CNN\nModel: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_24 (Conv2D)          (None, 222, 222, 32)      896       \n                                                                 \n max_pooling2d_24 (MaxPoolin  (None, 111, 111, 32)     0         \n g2D)                                                            \n                                                                 \n conv2d_25 (Conv2D)          (None, 109, 109, 64)      18496     \n                                                                 \n max_pooling2d_25 (MaxPoolin  (None, 54, 54, 64)       0         \n g2D)                                                            \n                                                                 \n conv2d_26 (Conv2D)          (None, 52, 52, 128)       73856     \n                                                                 \n max_pooling2d_26 (MaxPoolin  (None, 26, 26, 128)      0         \n g2D)                                                            \n                                                                 \n conv2d_27 (Conv2D)          (None, 24, 24, 128)       147584    \n                                                                 \n max_pooling2d_27 (MaxPoolin  (None, 12, 12, 128)      0         \n g2D)                                                            \n                                                                 \n flatten_6 (Flatten)         (None, 18432)             0         \n                                                                 \n dense_12 (Dense)            (None, 512)               9437696   \n                                                                 \n dense_13 (Dense)            (None, 2)                 1026      \n                                                                 \n=================================================================\nTotal params: 9,679,554\nTrainable params: 9,679,554\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_24 (Conv2D)          (None, 222, 222, 32)      896       \n                                                                 \n max_pooling2d_24 (MaxPoolin  (None, 111, 111, 32)     0         \n g2D)                                                            \n                                                                 \n conv2d_25 (Conv2D)          (None, 109, 109, 64)      18496     \n                                                                 \n max_pooling2d_25 (MaxPoolin  (None, 54, 54, 64)       0         \n g2D)                                                            \n                                                                 \n conv2d_26 (Conv2D)          (None, 52, 52, 128)       73856     \n                                                                 \n max_pooling2d_26 (MaxPoolin  (None, 26, 26, 128)      0         \n g2D)                                                            \n                                                                 \n conv2d_27 (Conv2D)          (None, 24, 24, 128)       147584    \n                                                                 \n max_pooling2d_27 (MaxPoolin  (None, 12, 12, 128)      0         \n g2D)                                                            \n                                                                 \n flatten_6 (Flatten)         (None, 18432)             0         \n                                                                 \n dense_12 (Dense)            (None, 512)               9437696   \n                                                                 \n dense_13 (Dense)            (None, 2)                 1026      \n                                                                 \n=================================================================\nTotal params: 9,679,554\nTrainable params: 9,679,554\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/30\n115/115 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.5087\nEpoch 1: val_loss improved from inf to 0.69120, saving model to /kaggle/working/checkpoints/CNN_best_iter1.h5\n115/115 [==============================] - 41s 349ms/step - loss: 0.6968 - accuracy: 0.5087 - val_loss: 0.6912 - val_accuracy: 0.5000\nEpoch 2/30\n115/115 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.5783\nEpoch 2: val_loss improved from 0.69120 to 0.68618, saving model to /kaggle/working/checkpoints/CNN_best_iter1.h5\n115/115 [==============================] - 41s 357ms/step - loss: 0.6885 - accuracy: 0.5783 - val_loss: 0.6862 - val_accuracy: 0.5000\nEpoch 3/30\n115/115 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.6152\nEpoch 3: val_loss improved from 0.68618 to 0.64870, saving model to /kaggle/working/checkpoints/CNN_best_iter1.h5\n115/115 [==============================] - 40s 350ms/step - loss: 0.6691 - accuracy: 0.6152 - val_loss: 0.6487 - val_accuracy: 0.6607\nEpoch 4/30\n115/115 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.6348\nEpoch 4: val_loss improved from 0.64870 to 0.63930, saving model to /kaggle/working/checkpoints/CNN_best_iter1.h5\n115/115 [==============================] - 40s 347ms/step - loss: 0.6391 - accuracy: 0.6348 - val_loss: 0.6393 - val_accuracy: 0.6250\nEpoch 5/30\n115/115 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.6935\nEpoch 5: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 347ms/step - loss: 0.6017 - accuracy: 0.6935 - val_loss: 0.6483 - val_accuracy: 0.6607\nEpoch 6/30\n115/115 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.7261\nEpoch 6: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 344ms/step - loss: 0.5625 - accuracy: 0.7261 - val_loss: 0.6540 - val_accuracy: 0.6607\nEpoch 7/30\n115/115 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7413\nEpoch 7: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 346ms/step - loss: 0.5241 - accuracy: 0.7413 - val_loss: 0.6959 - val_accuracy: 0.6429\nEpoch 8/30\n115/115 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.7413\nEpoch 8: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 352ms/step - loss: 0.5033 - accuracy: 0.7413 - val_loss: 0.6900 - val_accuracy: 0.5893\nEpoch 9/30\n115/115 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.7870\nEpoch 9: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 344ms/step - loss: 0.4691 - accuracy: 0.7870 - val_loss: 0.7876 - val_accuracy: 0.6607\nEpoch 10/30\n115/115 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8413\nEpoch 10: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 343ms/step - loss: 0.4094 - accuracy: 0.8413 - val_loss: 0.8591 - val_accuracy: 0.6607\nEpoch 11/30\n115/115 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.8239\nEpoch 11: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 352ms/step - loss: 0.3692 - accuracy: 0.8239 - val_loss: 0.8258 - val_accuracy: 0.6250\nEpoch 12/30\n115/115 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8674\nEpoch 12: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 349ms/step - loss: 0.3167 - accuracy: 0.8674 - val_loss: 0.8965 - val_accuracy: 0.6071\nEpoch 13/30\n115/115 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.8804\nEpoch 13: val_loss did not improve from 0.63930\n115/115 [==============================] - 41s 354ms/step - loss: 0.2760 - accuracy: 0.8804 - val_loss: 0.9856 - val_accuracy: 0.6071\nEpoch 14/30\n115/115 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9174\nEpoch 14: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 349ms/step - loss: 0.2330 - accuracy: 0.9174 - val_loss: 0.9685 - val_accuracy: 0.6429\nEpoch 15/30\n115/115 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9304\nEpoch 15: val_loss did not improve from 0.63930\n115/115 [==============================] - 41s 354ms/step - loss: 0.1870 - accuracy: 0.9304 - val_loss: 0.9980 - val_accuracy: 0.6786\nEpoch 16/30\n115/115 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9435\nEpoch 16: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 350ms/step - loss: 0.1572 - accuracy: 0.9435 - val_loss: 1.2973 - val_accuracy: 0.5893\nEpoch 17/30\n115/115 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9522\nEpoch 17: val_loss did not improve from 0.63930\n115/115 [==============================] - 41s 352ms/step - loss: 0.1277 - accuracy: 0.9522 - val_loss: 1.1898 - val_accuracy: 0.6786\nEpoch 18/30\n115/115 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9696\nEpoch 18: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 349ms/step - loss: 0.0990 - accuracy: 0.9696 - val_loss: 1.3302 - val_accuracy: 0.6964\nEpoch 19/30\n115/115 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9696\nEpoch 19: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 346ms/step - loss: 0.0984 - accuracy: 0.9696 - val_loss: 1.4367 - val_accuracy: 0.6607\nEpoch 20/30\n115/115 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9870\nEpoch 20: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 344ms/step - loss: 0.0761 - accuracy: 0.9870 - val_loss: 1.4953 - val_accuracy: 0.6429\nEpoch 21/30\n115/115 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9804\nEpoch 21: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 345ms/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 1.6328 - val_accuracy: 0.6607\nEpoch 22/30\n115/115 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9891\nEpoch 22: val_loss did not improve from 0.63930\n115/115 [==============================] - 39s 343ms/step - loss: 0.0447 - accuracy: 0.9891 - val_loss: 2.3497 - val_accuracy: 0.6786\nEpoch 23/30\n115/115 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9891\nEpoch 23: val_loss did not improve from 0.63930\n115/115 [==============================] - 39s 343ms/step - loss: 0.0466 - accuracy: 0.9891 - val_loss: 1.9860 - val_accuracy: 0.6429\nEpoch 24/30\n115/115 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9848\nEpoch 24: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 345ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 2.0732 - val_accuracy: 0.6786\nEpoch 25/30\n115/115 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9913\nEpoch 25: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 351ms/step - loss: 0.0427 - accuracy: 0.9913 - val_loss: 2.3770 - val_accuracy: 0.6786\nEpoch 26/30\n115/115 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9935\nEpoch 26: val_loss did not improve from 0.63930\n115/115 [==============================] - 39s 343ms/step - loss: 0.0370 - accuracy: 0.9935 - val_loss: 2.3440 - val_accuracy: 0.6250\nEpoch 27/30\n115/115 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9913\nEpoch 27: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 344ms/step - loss: 0.0477 - accuracy: 0.9913 - val_loss: 1.9673 - val_accuracy: 0.6429\nEpoch 28/30\n115/115 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9935\nEpoch 28: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 347ms/step - loss: 0.0447 - accuracy: 0.9935 - val_loss: 1.9645 - val_accuracy: 0.6607\nEpoch 29/30\n115/115 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9913\nEpoch 29: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 349ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 2.2481 - val_accuracy: 0.6429\nEpoch 30/30\n115/115 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9913\nEpoch 30: val_loss did not improve from 0.63930\n115/115 [==============================] - 40s 347ms/step - loss: 0.0368 - accuracy: 0.9913 - val_loss: 2.3049 - val_accuracy: 0.6964\n***Simple CNN Model Training Finished***\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"def train_efficient_net_model(train_data, train_label, val_data, val_label, tensorboard, pre_trained):\n    \"\"\"This functions trains the efficientnet model based on given parameters\n    Args:\n        train_data (list): the np array of training data\n        train_label (list): the np array of training labels\n        test_data (list): the np array of validation data\n        test_label (list): the bp array of validation labels\n        tensorboard (callback): tensorboard log callback\n        pre_trained (bool): this flag defines whether to use pre trained model or not\n    \"\"\"    \n    print(\"***Initiating Model : EfficientnetB0\")\n    model = efficientnet()\n    # define checkpoint for saving the best model\n    cp_callback = ModelCheckpoint(filepath='/kaggle/working/checkpoints/efficientnet_best_eff_net' + '.h5' ,save_weights_only=False, save_best_only=True, verbose=1)\n\n    # load pre trained data\n    if(pre_trained):\n        model.load_weights(config.paths['pre_trained_model_path'])\n    \n    # train the model\n    history_efficientnet = model.fit(train_data, train_label, \n                batch_size=4, \n                epochs=2, \n                validation_data=(val_data, val_label), \n                shuffle=True, \n                callbacks=[tensorboard, cp_callback])\n    \n    # save the model of the last epoch\n    model.save(\"/kaggle/working/models/efficientnet_last_eff_net\" + \".h5\")\n    print(\"***Efficientnet Model Training Finished***\")\n    plot_hist(history_efficientnet, figure_name=\"efficientnet\")","metadata":{"execution":{"iopub.status.busy":"2023-04-24T21:43:35.456543Z","iopub.execute_input":"2023-04-24T21:43:35.457057Z","iopub.status.idle":"2023-04-24T21:43:35.467205Z","shell.execute_reply.started":"2023-04-24T21:43:35.457019Z","shell.execute_reply":"2023-04-24T21:43:35.465816Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"train_efficient_net_model(train_data, train_label, val_data, val_label, tensorboard, False)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T21:43:39.655320Z","iopub.execute_input":"2023-04-24T21:43:39.656873Z","iopub.status.idle":"2023-04-24T21:47:31.687692Z","shell.execute_reply.started":"2023-04-24T21:43:39.656813Z","shell.execute_reply":"2023-04-24T21:47:31.686504Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"***Initiating Model : EfficientnetB0\nModel: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n efficientnetb0 (Functional)  (None, 2)                4052133   \n                                                                 \n=================================================================\nTotal params: 4,052,133\nTrainable params: 4,010,110\nNon-trainable params: 42,023\n_________________________________________________________________\nEpoch 1/2\n115/115 [==============================] - ETA: 0s - loss: 4.0824 - accuracy: 0.5130\nEpoch 1: val_loss improved from inf to 2.12085, saving model to /kaggle/working/checkpoints/efficientnet_best_eff_net.h5\n115/115 [==============================] - 108s 711ms/step - loss: 4.0824 - accuracy: 0.5130 - val_loss: 2.1209 - val_accuracy: 0.5000\nEpoch 2/2\n115/115 [==============================] - ETA: 0s - loss: 1.6795 - accuracy: 0.5522\nEpoch 2: val_loss improved from 2.12085 to 1.93473, saving model to /kaggle/working/checkpoints/efficientnet_best_eff_net.h5\n115/115 [==============================] - 78s 679ms/step - loss: 1.6795 - accuracy: 0.5522 - val_loss: 1.9347 - val_accuracy: 0.5000\n***Efficientnet Model Training Finished***\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"def process_img(img_path):\n    \"\"\"Process the input for inference\n    Args:\n        img_path (string): the imaged path from where input image is kept\n    Returns:\n        np.array: the processed input image\n    \"\"\"    \n    img = cv2.imread(img_path)\n    img = cv2.resize(img , (224, 224))\n    img = img.reshape((1, 224, 224, 3))\n    img = tf.keras.utils.normalize(img, axis=1)\n    return np.array(img)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:41:28.468060Z","iopub.execute_input":"2023-04-24T20:41:28.469388Z","iopub.status.idle":"2023-04-24T20:41:28.476334Z","shell.execute_reply.started":"2023-04-24T20:41:28.469337Z","shell.execute_reply":"2023-04-24T20:41:28.475099Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def get_prediction(img_path, model_path):\n    \"\"\"this function get the prediction of a given image from a given model\n    Args:\n        img_path (str): the image path from where input image is kept\n        model_path (_type_): the model path from where required model is kept\n    Returns:\n        string: predicted class name of the input image\n    \"\"\"    \n    # img_path = ROOT_IMG_PATH + \"/\" + class_name + \"/\" + img_name\n    processed_img = process_img(img_path)\n    model = tf.keras.models.load_model(model_path)\n    prediction = model.predict(processed_img)\n    label_number = np.argmax(prediction)\n    class_name = 'Adidas' if label_number == 0 else 'Nike'\n    return class_name","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:41:53.570130Z","iopub.execute_input":"2023-04-24T20:41:53.570547Z","iopub.status.idle":"2023-04-24T20:41:53.577232Z","shell.execute_reply.started":"2023-04-24T20:41:53.570508Z","shell.execute_reply":"2023-04-24T20:41:53.576196Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#single image inference\ninference_image_path = '/kaggle/input/adiadas-nike-shoes/dataset/test/nike/Image_10.jpg'\ninference_model_path = '/kaggle/working/models/CNN_last_iter_1.h5'\noutput_class_name = get_prediction(inference_image_path, inference_model_path)\nimg_name = inference_image_path.split(\"/\")[-1]\nprint(f\"The predicted label for image {img_name} is {output_class_name}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:44:36.799988Z","iopub.execute_input":"2023-04-24T20:44:36.800636Z","iopub.status.idle":"2023-04-24T20:44:37.606850Z","shell.execute_reply.started":"2023-04-24T20:44:36.800584Z","shell.execute_reply":"2023-04-24T20:44:37.605337Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 115ms/step\nThe predicted label for image Image_10.jpg is Nike\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_confusion_matrix(image_dir, model_path):\n    adidas_correct = 0\n    adidas_wrong = 0\n    nike_correct = 0\n    nike_wrong = 0\n    for class_name in os.listdir(image_dir):\n        for img_name in os.listdir(os.path.join(image_dir, class_name)):\n            output_class_name = get_prediction(os.path.join(image_dir, class_name, img_name), model_path)  \n            original_class_name = label_dict[img_name[:-4]]\n            print(output_class_name, class_name, original_class_name)\n            if original_class_name == 'Adidas':\n                if output_class_name == 'Adidas':\n                    adidas_correct += 1 \n                else:\n                    adidas_wrong += 1\n            elif original_class_name == 'Nike':\n                if output_class_name == 'Nike':\n                    nike_correct += 1 \n                else: \n                    nike_wrong += 1\n    return adidas_correct, adidas_wrong, nike_correct, nike_wrong","metadata":{"execution":{"iopub.status.busy":"2023-04-24T22:17:21.525844Z","iopub.execute_input":"2023-04-24T22:17:21.526674Z","iopub.status.idle":"2023-04-24T22:17:21.535449Z","shell.execute_reply.started":"2023-04-24T22:17:21.526626Z","shell.execute_reply":"2023-04-24T22:17:21.534329Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/models/CNN_last_iter_1.h5'\nimage_dir = '/kaggle/input/adiadas-nike-shoes/dataset/validation'\n\nadidas_correct, adidas_wrong, nike_correct, nike_wrong = generate_confusion_matrix(image_dir, model_path)\n\nprint(\"***The Confusion Matrix for test set***\")\nprint(\"Label -> Adidas , Nike\")\nprint(f'Adidas -> {adidas_correct}, {adidas_wrong}')\nprint(f'Nike -> {nike_wrong}, {nike_correct}')","metadata":{"execution":{"iopub.status.busy":"2023-04-24T22:17:24.257641Z","iopub.execute_input":"2023-04-24T22:17:24.258094Z","iopub.status.idle":"2023-04-24T22:18:08.051200Z","shell.execute_reply.started":"2023-04-24T22:17:24.258054Z","shell.execute_reply":"2023-04-24T22:18:08.049923Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 123ms/step\nNike nike Nike\n1/1 [==============================] - 0s 115ms/step\nNike nike Nike\n1/1 [==============================] - 0s 118ms/step\nNike nike Nike\n1/1 [==============================] - 0s 122ms/step\nNike nike Nike\n1/1 [==============================] - 0s 121ms/step\nNike nike Nike\n1/1 [==============================] - 0s 120ms/step\nNike nike Nike\n1/1 [==============================] - 0s 118ms/step\nAdidas nike Nike\n1/1 [==============================] - 0s 121ms/step\nNike nike Nike\n1/1 [==============================] - 0s 117ms/step\nNike nike Nike\n1/1 [==============================] - 0s 114ms/step\nAdidas nike Nike\n1/1 [==============================] - 0s 113ms/step\nNike nike Nike\n1/1 [==============================] - 0s 116ms/step\nNike nike Nike\n1/1 [==============================] - 0s 126ms/step\nNike nike Nike\n1/1 [==============================] - 0s 115ms/step\nNike nike Nike\n1/1 [==============================] - 0s 113ms/step\nNike nike Nike\n1/1 [==============================] - 0s 114ms/step\nNike nike Nike\n1/1 [==============================] - 0s 114ms/step\nNike nike Nike\n1/1 [==============================] - 0s 115ms/step\nNike nike Nike\n1/1 [==============================] - 0s 123ms/step\nNike nike Nike\n1/1 [==============================] - 0s 113ms/step\nNike nike Nike\n1/1 [==============================] - 0s 127ms/step\nAdidas nike Nike\n1/1 [==============================] - 0s 117ms/step\nNike nike Nike\n1/1 [==============================] - 0s 125ms/step\nNike nike Nike\n1/1 [==============================] - 0s 112ms/step\nNike nike Nike\n1/1 [==============================] - 0s 121ms/step\nNike nike Nike\n1/1 [==============================] - 0s 114ms/step\nNike nike Nike\n1/1 [==============================] - 0s 114ms/step\nAdidas nike Nike\n1/1 [==============================] - 0s 114ms/step\nNike nike Nike\n1/1 [==============================] - 0s 118ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 118ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 117ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 117ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 115ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 115ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 116ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 119ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 118ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 116ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 119ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 125ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 116ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 117ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 121ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 115ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 136ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 122ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 115ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 121ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 124ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 140ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 116ms/step\nNike adidas Adidas\n1/1 [==============================] - 0s 121ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 119ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 114ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 114ms/step\nAdidas adidas Adidas\n1/1 [==============================] - 0s 119ms/step\nAdidas adidas Adidas\n***The Confusion Matrix for test set***\nLabel -> Adidas , Nike\nAdidas -> 17, 11\nNike -> 4, 24\n","output_type":"stream"}]},{"cell_type":"code","source":"'''In this segment I have tried a simple CNN model and EfficientNet Backbone architecture to do this specific task.\n\nProblem in this task\n1. Number of Data is very low\n2. Few images does not represent specific shoes of that perticular set\n3. Logo is not visible in that show\n4. There was a wrong lebel on the CSV file\n\nApproaches that could have made improve performance of this task\n1. Transfer learning\n    Using a pre-trained model which have seen many images of this type that model could been used as a pre-trained model\n    for this task. I have kept the option to add pre-trained model in my code.\n2. Ensemble Learning\n    Ensemble learning would made the file model perform much better. I have implemented this code in my git repository code\n    but didn't have the time to add this code on this repo.\n3. Image Augmentation and Cleaning\n    The number of image given for this task is very low. There are some outlier images too. Data cleaning and adding augmented\n    image will surely improve performance of this task.\n4. Transformer Based object Detector\n    Currently transformer based object detector are working wonder. For this task this should have improved performance. But\n    this small dataset and images with low resolation that didn't seem required.\n\n'''","metadata":{},"execution_count":null,"outputs":[]}]}